{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Autor**: Álisson De Oliveira Alves\n",
    "#### **Site**: https://linktr.ee/devalissonalves\n",
    "#### **Disciplina**: Aprendizado de Máquina (PPGEEC2318)\n",
    "#### **Professor**: _IVANOVITCH MEDEIROS DANTAS DA SILVA_\n",
    "________________________________________________________________\n",
    "\n",
    "## Livro: Projetando sistemas de _Machine Learning_\n",
    "\n",
    "### Capítulo 4: _Data Training_\n",
    "\n",
    "#### PRINCIPAIS INSIGHTS DO CAPÍTULO\n",
    "\n",
    "* Contextualização _Data Training_\n",
    "_____________________________________\n",
    "\n",
    "**Insight 01**: Dados são confusos, complexos, imprevisíveis e potencialmente traiçoeiros. Caso não sejam manipulados de forma correta, podem arruinar facilmente toda a sua operação de ML. Os dados estão repletos de possíveis vieses. Esses vieses têm muitas causas possíveis e se originam durante a coleta, amostragem ou rotulagem. A partir dessas afimações, fica evidenciado a importância da preparação dos dados antes mesmo de serem incluídos nos sistemas de ML. Dessa maneira, o sucesso de uma aplicação que envolve _Machine Learning_ está diretamente associada a qualidade da ingestão de dados nos modelos.\n",
    "\n",
    "* _Amostragem_\n",
    "_____________________________________\n",
    "\n",
    "**Insight 02**: No que se refere a amostragem dos dados ela é importante em diferentes contextos, por exemplo: \n",
    "- Quando não temos acesso a todos os possíveis dados do mundo real, pois os que você usa para treinar seu modelo são um subconjunto de dados do mundo real, criado por um método de amostragem ou outro. \n",
    "\n",
    "- Outro caso é quando é inviável processar todos os dados que temos acesso, -- porque exige muito tempo ou recursos -- assim precisamos amostrá-los para criar um subconjunto viável de processar.\n",
    "\n",
    "**Insight 03** _Amostragem não probabilística_: A amostragem não probabilística é quando a seleção de dados não é baseada em nenhum critério de probabilidade. Esse tipo de amostra, que não possui um critério de não probabilidade não são representativas dos dados do mundo real, ou seja, estão repletas de vieses de seleção. \n",
    "\n",
    "**Insight 04** _Amostragem estratificada_: De maneira resumida, o objetivo desse tipo de amostragem divide a população (número total de amostras) em grupos que lhe interessam e a partir disso, realizar a amostragem de cada grupo separadamente. O desafio principal desse tipo é quando uma amostra pode estar presente em vários grupos, como no caso de tarefas multirótulos.\n",
    "\n",
    "**Insight 05** _Amostragem ponderada_: O conceito principal é que nesse contexto cada amostra recebe um peso, que determina a probabilidade de ser selecionada. Por exemplo, numa amostra A, B e C, e quisermos classificá-las em probabilidades percentuais de serem selecionadas, podemos atribuir os pesos, por exemplo: 0.5 (50%), 0.3 (30%) e 0.2 (20%). A amostragem ponderada é usada para selecionar amostras para treinar seu modelo, enquanto os pesos amostrais são usados para atribuir \"pesos\" ou \"importância\" às amostras de treinamento.\n",
    "\n",
    "* _Rotulagem_\n",
    "_____________________________________\n",
    "\n",
    "**Insight 06**: Apesar da promessa do machine learning não supervisionado, a maioria dos modelos de ML em produção hoje é supervisionada, ou seja: precisa de dados rotulados para aprender.\n",
    "\n",
    "**Insight 07** _Rótulos Manuais_: A rotulagem manual representa uma ameaça à privacidade dos dados. Na rotulagem manual, alguém (geralmente um especialista do contexto da aplicação) precisa examinar seus dados, o que nem sempre é possível se estes tiveram requisitos rigorosos de privacidade. Outro ponto acerca desse tipo de rotulagem é que o processo pode ser oneroso. O exemplo que a _Huyen_ trás no livro é um determinado pesquisador gastou cerca de um ano para rotular um conjunto de dados suficientes para classificar câncer de pulmão a partir de imagens de raio-x.\n",
    "\n",
    "**Insight 08** _Data lineage_: Um dos cuidados no processo de rotulagem é o _Crowdsourcing_ que tem como objetivo principal a unificação de diferentes pessoas em torno da realização de uma tarefa (rotulagem por exemplo) ou da solução de um problema. Dessa forma, caso os **anotadores** rotulem os dados com menos precisão do que os dados originais, o modelo pode não ter o desempenho satisfatório esperado. Dessa forma, é boa prática acompanhar as origens de cada uma das amostras (principalmente quando se tem várias fontes de dados), bem como seus rótulos. Essa técnica é conhecida como _Data Lineage_.\n",
    "\n",
    "**Insight 09** _Rotulagem Natural e extensão do loop de feedback_: Nas tarefas com rótulos naturais _Ground truth_, extensão do loop de feedback é o tempo que leva desde o momento em que uma predição é veiculada até o momento em que o feedback é fornecido.\n",
    "\n",
    "**Insight 10** _Weak Supervision_: A ideia da weak supervision é as pessoas recorrerem as heurísticas, que podem ser desenvolvidas por especialistas no assunto para rotular os dados. \n",
    "\n",
    "Exemplo: \n",
    "\n",
    "def labeling_function(note):\n",
    "    if \"pneumonia\" in note: \n",
    "        return \"EMERGENT\"\n",
    "\n",
    "Em teoria, não é necessário rótulos manuais para a weak supervision. No entanto, para se ter uma noção da acurácia de suas LFs (Labeling Functions), recomenda-se um pequeno número de rótulos manuais para validação.\n",
    "\n",
    "**Insight 11** _Semisupervisão_: Um método clássico de semisupervisão é o _self-trining_. Basta treinar um modelo em seu conjunto existente de dados rotulados e usá-lo para fazer predições de amostras não rotuladas. Supondo que as predições com altos scores de probabilidades brutas estejam corretas, basta adicionar os rótulos preditos de alta probabilidade ao seu conjunto de treinamento e treinar um modelo novo neste conjunto de treinamento expandido. Dado na literatura o principal objetivo de se utilizar uma abordagem baseada em semisupervisão, ocorre quando temos um número de amostras rotuladas para o treinamento limitados. Na semisupervisão com dados limitados, é necessário considerar o quanto desses dados limitados devemos usar para avaliar vários modelos candidatos e selecionar o melhor.\n",
    "\n",
    "**Insight 12** _Transfer Learning (Aprendizado por transferência)_: O aprendizado por transferência diz respeito à família de métodos em que um modelo desenvolvido para uma tarefa é **reutilizado** como ponto de partida para um modelo em uma segunda tarefa. Primeiro, treina-se o modelo-base para uma tarefa-base.\n",
    "\n",
    "**Insight 13** _Aprendizado Ativo_: O aprendizado ativo é um método para melhorar a eficiência dos rótulos de dados. No aprendizado ativo, espera-se que os modelos de ML possam alcançar maior acurácia com menos rótulos de treinamento se puderem escolher com quais amostras de dados aprender. Por exemplo, em vez de rotular amostras de dados aleatoriamente você rotula as amostras que são mais úteis para seus modelos de acordo com algumas métricas ou heurísticas. A métrica mais simples é a medição de incerteza. Ou seja, rotule os exemplos que os seus modelos tem menos certeza, esperando que o ajudem a aprender melhor a fronteira de decisão.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INSIGHTS EXTRAS\n",
    "\n",
    "* _Classes Desbalanceadas_\n",
    "_____________________________________\n",
    "\n",
    "**Insight 14** _Classes Desbalanceadas_: Classes desbalanceadas normalmente representam o problema nas tarefas de classificação em que há uma diferença substancial no número de amostras em cada classes dos dados de treinamento. As classes desbalanceadas também podem ocorrer em tarefas de regressão onde os rótulos são contínuos. \n",
    "\n",
    "- **Principais desafios** - As classes desbalanceadas podem dificultar o aprendizado por três motivos:\n",
    "\n",
    "    1. Em geral, classes desbalanceadas não têm sinal suficiente (força) para seu modelo aprender e detectar classes minoritárias; \n",
    "    2. Classes desbalanceadas facilitam com que seu modelo fique preso em uma solução não ideal, explorando uma heurística simples em vez de aprender qualquer coisa útil sobre o padrão subjacente aos dados;\n",
    "    3. Classes desbalanceadas resultam em custos assimétricos de erro - o custo de uma predição incorreta em uma amostra de classe rara pode ser bem maior do que a predição incorretaem uma de classe majoritária.\n",
    "\n",
    "Exemplos clássicos: \n",
    "    - Detecção de fraudes, onde a maioria das transações (amostras comuns sem anomalias) com cartão de crédito não é fraudulenta. \n",
    "    - Outro exemplo a ser considerado é numa tarefa de detecção de objetos. Onde modelo tem o objetivo principal de identificar/detectar construções, prédios e etc... porém, 70% das amostras são de vegetação, lagos e montanhas.\n",
    "\n",
    "* _Data Augmentation_\n",
    "_____________________________________\n",
    "**Insight 15**: A técnica de _data augmentation_ é uma família de técnicas usadas para aumentar a quantidade de dados de treinamento. Essas técnicas são usadas tradicionalmente em tarefas com dados de treinamento limitado, como imagens médicas. \n",
    "\n",
    "O _data augmentation_ se tornou etapa padrão em muitas tarefas de visão computacional e está sendo usados em tarefas de processamento de linguagem natural. \n",
    "\n",
    "- *Transformações simples de preservação de rótulos*: Em visão computacional, a técnica mais simples é modificar aleatoriamente uma imagem preservando seu rótulo. Isso é possível por meio de técnicas como - [CROPPING, FLIPPING, ROTATION, INVERSION]. As imagens transformadas são geradas em Python na CPU enquanto a GPU está treinando no lote anterior de imagens. \n",
    "\n",
    "- *Perturbação*: Adicionar uma pequena quantidade de ruído a uma imagem pode fazer com que uma rede neural a classifique erroneamente. *[Su, et. al]* evidenciou que 67.97% das imagens naturais no conjunto de teste de dados do Kaggle CIFAR-10 e 16.04% das imagens de teste do ImageNet podem ser classificadas incorretamente alterando apenas um pixel. O uso de dados enganosos com o objetivo de engnar uma rede neural e induzi-la a fazer predições incorretas é conhecido como ataque adversário. Adicionar amostras ruidosas ao treinamento pode ajudar os modelos a reconhecer os pontos fracos em sua fronteira de decisão aprendida e melhorar seu desempenho.\n",
    "\n",
    "- *Síntese de Dados*: O uso de redes neurais para sintetizar dados de treinamento é uma abordagem interessante que está em constante pesquisa, mas ainda não é popular em produção. *[Sandfort, et. al]* mostraram que, ao adicionar imagens geradas com uma CycleGAN aos seus dados de treinamento originais, eles foram capazes de melhorar significativamente o desempenho de seu modelo em tarefas de segmentação de tomografia computadorizada. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESUMO FINAL\n",
    "\n",
    "Toda a grande área do aprendizado de máquina é sustentada pelos insights e contextos discorridos anteriormente. Cada um dos aspectos estão diretamente relacionados com a perfomance, robustez e eficiência dos modelos gerados. No que se refere aos treinamentos dos modelos, o ato de treinar um modelo a partir de dados se reflete na substancia principal que moldará o aprendizado / conhecimento da *máquina*. Dessa forma, exige-se que profissionais da área de IA, realizemos um processo criterioso de manipulação dos dados: seleção, preparação, limpeza e etc. A seleção cuidadosa e calculada de dados é fundamental para prevenir distorções e assegurar a aplicabilidade do modelo a novos conjuntos de dados, principalmente se a aplicação estiver funcionando em um contexto de produção. Por sua vez, a precisão na rotulagem é fundamental para instruir os modelos sobre os detalhes sutis dos dados, concedendo-lhes sentido e contexto, assim como a importância de se evitar (quando possível) o desbalanceamento das classes, prevenindo comportamentos que prejudiquem o objetivo principal da aplicação, assegurando o equilíbrio entre as classes envolvidas no problema. Por fim, o data augmentation surge como uma técnica que promove o aumento sintético dos dados, fortalecendo o conjunto de dados incluindo variações que facilitam o reconhecimento de padrões no contexto que os algoritmos forem aplicados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Checar as citações abaixo_\n",
    "_____________________________________\n",
    "\n",
    "@article{su2019one,\n",
    "  title={One pixel attack for fooling deep neural networks},\n",
    "  author={Su, Jiawei and Vargas, Danilo Vasconcellos and Sakurai, Kouichi},\n",
    "  journal={IEEE Transactions on Evolutionary Computation},\n",
    "  volume={23},\n",
    "  number={5},\n",
    "  pages={828--841},\n",
    "  year={2019},\n",
    "  publisher={IEEE}\n",
    "}\n",
    "\n",
    "@article{sandfort2019data,\n",
    "  title={Data augmentation using generative adversarial networks (CycleGAN) to improve generalizability in CT segmentation tasks},\n",
    "  author={Sandfort, Veit and Yan, Ke and Pickhardt, Perry J and Summers, Ronald M},\n",
    "  journal={Scientific reports},\n",
    "  volume={9},\n",
    "  number={1},\n",
    "  pages={16884},\n",
    "  year={2019},\n",
    "  publisher={Nature Publishing Group UK London}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
