{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Autor**: Álisson De Oliveira Alves\n",
    "#### **Site**: https://linktr.ee/devalissonalves\n",
    "#### **Disciplina**: Aprendizado de Máquina (PPGEEC2318)\n",
    "#### **Professor**: _IVANOVITCH MEDEIROS DANTAS DA SILVA_\n",
    "________________________________________________________________\n",
    "\n",
    "## Livro: Projetando sistemas de _Machine Learning_\n",
    "\n",
    "### Capítulo 4: _Data Training_\n",
    "\n",
    "#### PRINCIPAIS INSIGHTS DO CAPÍTULO 04\n",
    "\n",
    "* Contextualização _Data Training_\n",
    "_____________________________________\n",
    "\n",
    "**Insight 01**: Dados são confusos, complexos, imprevisíveis e potencialmente traiçoeiros. Caso não sejam manipulados de forma correta, podem arruinar facilmente toda a sua operação de ML. Os dados estão repletos de possíveis vieses. Esses vieses têm muitas causas possíveis e se originam durante a coleta, amostragem ou rotulagem. A partir dessas afimações, fica evidenciado a importância da preparação dos dados antes mesmo de serem incluídos nos sistemas de ML. Dessa maneira, o sucesso de uma aplicação que envolve _Machine Learning_ está diretamente associada a qualidade da ingestão de dados nos modelos.\n",
    "\n",
    "* _Amostragem_\n",
    "_____________________________________\n",
    "\n",
    "**Insight 02**: No que se refere a amostragem dos dados ela é importante em diferentes contextos, por exemplo: \n",
    "- Quando não temos acesso a todos os possíveis dados do mundo real, pois os que você usa para treinar seu modelo são um subconjunto de dados do mundo real, criado por um método de amostragem ou outro. \n",
    "\n",
    "- Outro caso é quando é inviável processar todos os dados que temos acesso, -- porque exige muito tempo ou recursos -- assim precisamos amostrá-los para criar um subconjunto viável de processar.\n",
    "\n",
    "**Insight 03** _Amostragem não probabilística_: A amostragem não probabilística é quando a seleção de dados não é baseada em nenhum critério de probabilidade. Esse tipo de amostra, que não possui um critério de não probabilidade não são representativas dos dados do mundo real, ou seja, estão repletas de vieses de seleção. \n",
    "\n",
    "**Insight 04** _Amostragem estratificada_: De maneira resumida, o objetivo desse tipo de amostragem divide a população (número total de amostras) em grupos que lhe interessam e a partir disso, realizar a amostragem de cada grupo separadamente. O desafio principal desse tipo é quando uma amostra pode estar presente em vários grupos, como no caso de tarefas multirótulos.\n",
    "\n",
    "**Insight 05** _Amostragem ponderada_: O conceito principal é que nesse contexto cada amostra recebe um peso, que determina a probabilidade de ser selecionada. Por exemplo, numa amostra A, B e C, e quisermos classificá-las em probabilidades percentuais de serem selecionadas, podemos atribuir os pesos, por exemplo: 0.5 (50%), 0.3 (30%) e 0.2 (20%). A amostragem ponderada é usada para selecionar amostras para treinar seu modelo, enquanto os pesos amostrais são usados para atribuir \"pesos\" ou \"importância\" às amostras de treinamento.\n",
    "\n",
    "* _Rotulagem_\n",
    "_____________________________________\n",
    "\n",
    "**Insight 06**: Apesar da promessa do machine learning não supervisionado, a maioria dos modelos de ML em produção hoje é supervisionada, ou seja: precisa de dados rotulados para aprender.\n",
    "\n",
    "**Insight 07** _Rótulos Manuais_: A rotulagem manual representa uma ameaça à privacidade dos dados. Na rotulagem manual, alguém (geralmente um especialista do contexto da aplicação) precisa examinar seus dados, o que nem sempre é possível se estes tiveram requisitos rigorosos de privacidade. Outro ponto acerca desse tipo de rotulagem é que o processo pode ser oneroso. O exemplo que a _Huyen_ trás no livro é um determinado pesquisador gastou cerca de um ano para rotular um conjunto de dados suficientes para classificar câncer de pulmão a partir de imagens de raio-x.\n",
    "\n",
    "**Insight 08** _Data lineage_: Um dos cuidados no processo de rotulagem é o _Crowdsourcing_ que tem como objetivo principal a unificação de diferentes pessoas em torno da realização de uma tarefa (rotulagem por exemplo) ou da solução de um problema. Dessa forma, caso os **anotadores** rotulem os dados com menos precisão do que os dados originais, o modelo pode não ter o desempenho satisfatório esperado. Dessa forma, é boa prática acompanhar as origens de cada uma das amostras (principalmente quando se tem várias fontes de dados), bem como seus rótulos. Essa técnica é conhecida como _Data Lineage_.\n",
    "\n",
    "**Insight 09** _Rotulagem Natural e extensão do loop de feedback_: Nas tarefas com rótulos naturais _Ground truth_, extensão do loop de feedback é o tempo que leva desde o momento em que uma predição é veiculada até o momento em que o feedback é fornecido.\n",
    "\n",
    "**Insight 10** _Weak Supervision_: A ideia da weak supervision é as pessoas recorrerem as heurísticas, que podem ser desenvolvidas por especialistas no assunto para rotular os dados. \n",
    "\n",
    "Exemplo: \n",
    "\n",
    "def labeling_function(note):\n",
    "    if \"pneumonia\" in note: \n",
    "        return \"EMERGENT\"\n",
    "\n",
    "Em teoria, não é necessário rótulos manuais para a weak supervision. No entanto, para se ter uma noção da acurácia de suas LFs (Labeling Functions), recomenda-se um pequeno número de rótulos manuais para validação. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
